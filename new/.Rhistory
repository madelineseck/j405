geom_point(color = "purple", size = 3) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink")
)
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = 3) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink")
) +
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = ) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink") +
) +
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = ) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink")
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = ) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink")
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = 3) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink")
) +
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = 3) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink")
) +
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = 3) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink") +
labs(
title = "Relationship Between Temperature and Murders in Prince George's County",
x = "Average Temperature (°F)",
y = "Number of Murders"
) +
theme_minimal()
pg_murder_temps |>
ggplot(aes(x = temperature, y = murders, label = month)) +
geom_point(color = "purple", size = 5) +
geom_text(vjust = -1) +
geom_smooth(method = "lm", se = FALSE, color = "pink") +
labs(
title = "Relationship Between Temperature and Murders in Prince George's County",
x = "Average Temperature (°F)",
y = "Number of Murders"
) +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
options(scipen=999)
library(tidyverse)
# Known information about home values before the transit line
prior_mean <- 285000  # average home value
prior_sd <- 32000     # standard deviation
# Home sale prices after the transit line opened (14 homes)
new_prices <- c(297000, 305000, 292000, 318000, 290000, 311000, 299000,
325000, 302000, 288000, 307000, 315000, 320000, 294000)
# Create a journalist-friendly dataset
home_data <- tibble(
sale_id = 1:14,
sale_price = new_prices
)
# View the data
home_data
# Calculate statistics on the new home price data
new_stats <- home_data |>
summarise(
mean = mean(sale_price),
sd = sd(sale_price),
n = n(),
min = min(sale_price),
max = max(sale_price)
)
new_stats
# Function to format currency values
dollar_format <- function(x) {
paste0("$", format(x/1000, big.mark=","), "K")
}
# Create a visualization of home prices with reference to previous average
ggplot(home_data, aes(x = reorder(sale_id, sale_price), y = sale_price)) +
geom_col(fill = "seagreen", alpha = 0.8) +
geom_hline(yintercept = prior_mean, color = "darkred", size = 1, linetype = "dashed") +
annotate("text", x = 3, y = prior_mean - 8000,
label = "Previous Average ($285K)", hjust = 0, fontface = "bold", color = "darkred") +
scale_y_continuous(labels = dollar_format) +
labs(
title = "Home Sales After Transit Line",
subtitle = "Horizontal line shows previous neighborhood average of $285,000",
x = "Recent Home Sales",
y = "Sale Price",
caption = "Source: County Property Records"
) +
theme_minimal() +
theme(
plot.title = element_text(face = "bold", size = 14),
plot.subtitle = element_text(size = 10),
axis.text.x = element_blank(),
axis.ticks.x = element_blank()
)
# Perform a one-sample t-test
# Since we want to know if home values increased, we use a one-sided test (alternative = "greater")
t_test_result <- t.test(
home_data$sale_price,
mu = prior_mean,
alternative = "greater"
)
# Display the results
t_test_result
p_value <- t_test_result$p.value
format(p_value, scientific = FALSE)
# Extract the p-value
p_value <- t_test_result$p.value
# Calculate the 95% confidence interval
ci <- t.test(home_data$sale_price)$conf.int
# Format and display the confidence interval in a readable way
ci_formatted <- tibble(
`Lower bound` = dollar_format(ci[1]),
`Upper bound` = dollar_format(ci[2]),
`Confidence level` = "95%"
)
# Display as a nice table
ci_formatted
# Set our significance level
alpha <- 0.05
# Compare and make a decision
if(p_value < alpha) {
conclusion <- "The data provides statistical evidence supporting the claim that the transit line has increased home values."
} else {
conclusion <- "The data does not provide strong statistical evidence that the transit line has increased home values."
}
# Create a tibble to display the key statistics for your story
story_stats <- tibble(
`Previous average` = dollar_format(prior_mean),
`New average` = dollar_format(mean(new_prices)),
`Increase` = dollar_format(mean(new_prices) - prior_mean),
`Percent change` = paste0(round(((mean(new_prices) - prior_mean) / prior_mean) * 100, 1), "%"),
`p-value` = p_value,
p_value_formatted = format(p_value, scientific = FALSE),
`Statistically significant?` = if_else(p_value < alpha, "Yes", "No")
)
# Display the key statistics
story_stats
print(conclusion)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# Known information about reading scores before the new program
prior_mean <- REPLACE_ME  # average score
# Known information about reading scores before the new program
prior_mean <-72.6  # average score
prior_sd <- 4.8     # standard deviation
# Reading scores after implementing the new program (12 classrooms)
new_scores <- c(74, 76, 73, 75, 78, 77, 74, 79, 75, 76, 77, 75) # Replace with the actual scores
# Create a journalist-friendly dataset
score_data <- tibble(
classroom = paste("Classroom", 1:12),
reading_score = new_scores
)
# View the data
score_data
# Calculate statistics based on the new reading scores
new_stats <- score_data |>
summarise(
mean = mean(reading_score),
sd = sd(reading_score),
n = n()
)
new_stats
# STUDENT TASK: Choose an appropriate fill color for the bars
my_fill_color <- "blue" # Replace with a color name like "royalblue", "darkgreen", etc.
# Create a visualization comparing new scores to the previous average
score_data |>
ggplot(aes(x = classroom, y = reading_score)) +
geom_col(fill = my_fill_color, alpha = 0.8) +
geom_hline(yintercept = prior_mean, color = "darkred", size = 1, linetype = "dashed") +
annotate("text", x = 2, y = prior_mean - 1,
label = "Previous Average (72.6)",  hjust = -0.5, vjust= 2, fontface = "bold", color = "darkred") +
labs(
title = "Reading Scores After New Program Implementation",
subtitle = "Horizontal line shows previous district average of 72.6 points",
x = NULL,
y = "Reading Test Score",
caption = "Source: District Assessment Data"
) +
theme_minimal() +
theme(
plot.title = element_text(face = "bold", size = 14),
plot.subtitle = element_text(size = 10),
axis.text.x = element_text(angle = 45, hjust = 1)
)
# Set the significance level for your test
alpha_level <- 0.05 # Replace with the appropriate value
# Perform a one-sample t-test
# Since we want to know if scores improved (increased), we use a one-sided test (alternative = "greater")
t_test_result <- t.test(
score_data$reading_score,
mu = prior_mean,
alternative = "greater"
)
# Display the results
t_test_result
# Get the p-value
p_value <- t_test_result$p.value
# Calculate the 95% confidence interval
ci <- t.test(score_data$reading_score)$conf.int
# Create a tibble to display the key statistics for your story
story_stats <- tibble(
`Previous average` = prior_mean,
`New average` = mean(REPLACE_ME),
`Improvement` = mean(new_scores) - prior_mean,
`Percent change` = round(((mean(new_scores) - prior_mean) / prior_mean) * 100, 1),
`p-value` = p_value,
`Lower bound` = ci[1],
`Upper bound` = ci[2],
`Confidence level` = "95%"
)
# Get the p-value
p_value <- t_test_result$p.value
# Calculate the 95% confidence interval
ci <- t.test(score_data$reading_score)$conf.int
# Create a tibble to display the key statistics for your story
story_stats <- tibble(
`Previous average` = prior_mean,
`New average` = mean(new_scores),
`Improvement` = mean(new_scores) - prior_mean,
`Percent change` = round(((mean(new_scores) - prior_mean) / prior_mean) * 100, 1),
`p-value` = p_value,
`Lower bound` = ci[1],
`Upper bound` = ci[2],
`Confidence level` = "95%"
)
# Display the key statistics
story_stats
knitr::opts_chunk$set(echo = TRUE)
# LOAD THE TIDYVERSE
knitr::opts_chunk$set(echo = TRUE)
# LOAD THE TIDYVERSE
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# Read the data
car_thefts <- read_csv("https://raw.githubusercontent.com/dwillis/jour405/refs/heads/main/data/car_thefts_month.csv")  |>
arrange(month)  # Sort by date
# Basic inspection of the data
glimpse(car_thefts)
car_thefts |>
ggplot(aes(x = month, y = total)) +
geom_line(color = "steelblue", size = 1) +
geom_point(color = "darkblue", size = 3) +
labs(
title = "Monthly Car Thefts (July 2023 - February 2025)",
subtitle = "Is there a trend over time?",
x = "Month",
y = "Number of Car Thefts"
) +
theme_minimal() +
theme(
plot.title = element_text(face = "bold", size = 14),
axis.title = element_text(face = "bold")
)
theft_summary <- car_thefts |>
summarize(
mean_thefts = mean(total),
sd_thefts = sd(total),
months = n(),
se_thefts = sd_thefts / sqrt(months),
margin_error = qt(0.975, df = months - 1) * se_thefts,  # Using t-distribution for small sample
ci_lower = mean_thefts - margin_error,
ci_upper = mean_thefts + margin_error
)
# Display the confidence interval
theft_summary
# Make a better chart
car_thefts |>
ggplot(aes(x = month, y = total)) +
geom_line(color = "steelblue", alpha = 0.7) +
geom_point(size = 2) +
geom_hline(yintercept = theft_summary$mean_thefts, linetype = "dashed", color = "red", size = 1) +
geom_ribbon(aes(ymin = theft_summary$ci_lower, ymax = theft_summary$ci_upper),
fill = "red", alpha = 0.2) +
annotate("text", x = min(car_thefts$month),
y = theft_summary$mean_thefts + 10,
label = paste0("Mean: ", round(theft_summary$mean_thefts, 1)),
hjust = 0, color = "red") +
labs(
title = "Monthly Car Thefts with 95% Confidence Interval for the Mean",
x = "Month",
y = "Number of Car Thefts"
) +
theme_minimal()
# Find the halfway point and add a column placing each month in the first or second halves
midpoint <- ceiling(nrow(car_thefts) / 2)
car_thefts <- car_thefts |>
mutate(period = if_else(row_number() <= midpoint, "First Half", "Second Half"))
# Perform t-test comparing the two time periods - this is a two-sided test because we have two periods
t_test_periods <- t.test(total ~ period, data = car_thefts)
# Display results
t_test_periods
# Visualize the comparison
period_summary <- car_thefts |>
group_by(period) |>
summarize(
mean_thefts = mean(REPLACE_ME),
sd_thefts = sd(total),
months = n(),
se_thefts = sd_thefts / sqrt(months),
margin_error = qt(0.975, df = REPLACE_ME - 1) * se_thefts, # look at how we calculated this above
ci_lower = mean_thefts - margin_error,
ci_upper = mean_thefts + margin_error
)
# Find the halfway point and add a column placing each month in the first or second halves
midpoint <- ceiling(nrow(car_thefts) / 2)
car_thefts <- car_thefts |>
mutate(period = if_else(row_number() <= midpoint, "First Half", "Second Half"))
# Perform t-test comparing the two time periods - this is a two-sided test because we have two periods
t_test_periods <- t.test(total ~ period, data = car_thefts)
# Display results
t_test_periods
# Visualize the comparison
period_summary <- car_thefts |>
group_by(period) |>
summarize(
mean_thefts = mean(total),
sd_thefts = sd(total),
months = n(),
se_thefts = sd_thefts / sqrt(months),
margin_error = qt(0.975, df = months() - 1) * se_thefts, # look at how we calculated this above
ci_lower = mean_thefts - margin_error,
ci_upper = mean_thefts + margin_error
)
# Find the halfway point and add a column placing each month in the first or second halves
midpoint <- ceiling(nrow(car_thefts) / 2)
car_thefts <- car_thefts |>
mutate(period = if_else(row_number() <= midpoint, "First Half", "Second Half"))
# Perform t-test comparing the two time periods - this is a two-sided test because we have two periods
t_test_periods <- t.test(total ~ period, data = car_thefts)
# Display results
t_test_periods
# Visualize the comparison
period_summary <- car_thefts |>
group_by(period) |>
summarize(
mean_thefts = mean(total),
sd_thefts = sd(total),
months = n(),
se_thefts = sd_thefts / sqrt(months),
margin_error = qt(0.975, df = months - 1) * se_thefts, # look at how we calculated this above
ci_lower = mean_thefts - margin_error,
ci_upper = mean_thefts + margin_error
)
period_summary |>
ggplot(aes(x = period, y = mean_thefts, fill = period)) +
geom_col() +
geom_errorbar(aes(ymin = ci_lower, ymax = ci_upper), width = 0.2) +
geom_text(aes(label = round(mean_thefts, 1)), vjust = -0.5, size = 4) +
labs(
title = "Comparing Car Thefts: First Half vs. Second Half of Data Period",
subtitle = paste0("p-value = ", round(t_test_periods$p.value, 3)),
x = "Time Period",
y = "Average Number of Car Thefts"
) +
scale_fill_manual(values = c("First Half" = "#66c2a5", "Second Half" = "#fc8d62")) +
theme_minimal() +
theme(legend.position = "none")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(tidyverse)
# Load the dataset
nonvoters_data <- read_csv("https://raw.githubusercontent.com/dwillis/jour405_files/refs/heads/main/nonvoters_data.csv")
# Take a quick look at the data structure
glimpse(nonvoters_data)
education_distribution <- nonvoters_data |>
count(educ) |>
mutate(percentage = n / sum(n) * 100)
education_distribution
# Calculate unweighted voting intentions by education
unweighted_by_education <- nonvoters_data |>
# Filter out missing values
filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
# Group by education and response
group_by(educ, Q21) |>
# Count responses
summarize(count = n(), .groups = "drop_last") |>
# Calculate percentages
mutate(total = sum(count),
percentage = count / total * 100) |>
ungroup()
# Create a more readable format with voting intentions as columns
unweighted_educ_summary <- unweighted_by_education |>
pivot_wider(
id_cols = educ,
names_from = Q21,
values_from = percentage,
names_prefix = "pct_"
) |>
rename(
"Yes (%)" = pct_1,
"No (%)" = pct_2,
"Unsure (%)" = pct_3
)
unweighted_educ_summary
weighted_by_education <- nonvoters_data |>
# Filter out missing values
filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
# Group by education and response
group_by(educ, Q21) |>
# Sum the weights instead of counting
summarize(weighted_count = sum(weighted_count), .groups = "drop_last") |>
# Calculate weighted percentages
mutate(weighted_total = sum(weighted_count),
weighted_percentage = weighted_count / weighted_total * 100) |>
ungroup()
weighted_by_education <- nonvoters_data |>
# Filter out missing values
filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
# Group by education and response
group_by(educ, Q21) |>
# Sum the weights instead of counting
summarize(weighted_count = sum(weighted_count), .groups = "drop_last") |>
# Calculate weighted percentages
mutate(weighted_total = sum(weighted_count),
weighted_percentage = weighted_count / weighted_total * 100) |>
ungroup()
weighted_by_education <- nonvoters_data |>
# Filter out missing values
filter(!is.na(Q21), Q21 > 0, !is.na(educ)) |>
# Group by education and response
group_by(educ, Q21) |>
# Sum the weights instead of counting
summarize(weighted_count = sum(weight), .groups = "drop_last") |>
# Calculate weighted percentages
mutate(weighted_total = sum(weighted_count),
weighted_percentage = weighted_count / weighted_total * 100) |>
ungroup()
# Create a more readable format
weighted_educ_summary <- weighted_by_education |>
pivot_wider(
id_cols = educ,
names_from = Q21,
values_from = weighted_percentage,
names_prefix = "pct_"
) |>
rename(
"Yes (%)" = pct_1,
"No (%)" = pct_2,
"Unsure (%)" = pct_3
)
weighted_educ_summary
View(score_data)
comparison <- unweighted_educ_summary |>
inner_join(weighted_educ_summary, by = "educ", suffix = c("_unweighted", "_weighted")) |>
mutate(
# Calculate the differences between weighted and unweighted percentages
yes_diff = `Yes (%)_weighted` - `Yes (%)_unweighted`,
no_diff = `No (%)_weighted` - `No (%)_unweighted`,
unsure_diff = `Unsure (%)_weighted` - `Unsure (%)_unweighted`
) |>
# Select just the columns we want to display
select(educ, yes_diff, no_diff, unsure_diff) |>
rename(
"Education Level" = educ,
"Yes (% point diff)" = yes_diff,
"No (% point diff)" = no_diff,
"Unsure (% point diff)" = unsure_diff
)
comparison
educ_viz_data <- bind_rows(
# Unweighted data
unweighted_by_education |>
filter(Q21 == 1) |>  # Only "Yes" responses (Q21=1)
mutate(Type = "Unweighted") |>
select(Type, educ, percentage),
# Weighted data -
weighted_by_education |>
filter(Q21 == 1) |>  # Only "Yes" responses
mutate(
Type = "Weighted",
percentage = weighted_percentage
) |>
select(Type, educ, percentage)
)
# Create a grouped bar chart
ggplot(educ_viz_data,
aes(x = educ, y = percentage, fill = Type)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = sprintf("%.1f%%", percentage)),
position = position_dodge(width = 0.9), vjust = -0.5) +
labs(
title = "Weighted vs. Unweighted 'Yes' Responses by Education",
subtitle = "Q21: Do you plan to vote in the November election?",
y = "Percentage (%)",
x = "Education Level"
) +
scale_fill_manual(values = c("Unweighted" = "#619CFF", "Weighted" = "#F8766D")) +
theme_minimal() +
theme(
plot.title = element_text(face = "bold"),
legend.position = "bottom"
)
View(nonvoters_data)
View(t_test_result)
